{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fa436fb7a30>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# for reproducibility\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 64\n",
    "\n",
    "dataset = datasets.ImageFolder(root='../',\n",
    "                           transform=transforms.Compose([\n",
    "                               transforms.Resize(image_size),\n",
    "                               transforms.CenterCrop(image_size),\n",
    "                               transforms.ToTensor(),\n",
    "                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                           ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n",
    "                                         shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngpu = 1\n",
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "print(device)\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "cuda runtime error (999) : unknown error at /pytorch/aten/src/THC/THCGeneral.cpp:47",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-464ebd15209b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"off\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training Images\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_grid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    188\u001b[0m             raise AssertionError(\n\u001b[1;32m    189\u001b[0m                 \"libcudart functions unavailable. It looks like you have a broken build?\")\n\u001b[0;32m--> 190\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m         \u001b[0;31m# Some of the queued calls may reentrantly call _lazy_init();\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0;31m# we need to just return without initializing in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cuda runtime error (999) : unknown error at /pytorch/aten/src/THC/THCGeneral.cpp:47"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torchvision.utils as vutils\n",
    "real_batch = next(iter(dataloader))\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Training Images\")\n",
    "plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=2, normalize=True).cpu(),(1,2,0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_discriminator_block(input_dim, output_dim):\n",
    "    '''\n",
    "    Discriminator Block\n",
    "    Function for returning a neural network of the discriminator given input and output dimensions.\n",
    "    Parameters:\n",
    "        input_dim: the dimension of the input vector, a scalar\n",
    "        output_dim: the dimension of the output vector, a scalar\n",
    "    Returns:\n",
    "        a discriminator neural network layer, with a linear transformation \n",
    "          followed by an nn.LeakyReLU activation with negative slope of 0.2 \n",
    "          (https://pytorch.org/docs/master/generated/torch.nn.LeakyReLU.html)\n",
    "    '''\n",
    "    return nn.Sequential(\n",
    "        #### START CODE HERE ####\n",
    "        nn.Linear(input_dim, output_dim),\n",
    "        nn.LeakyReLU(0.2),\n",
    "        #### END CODE HERE ####\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "def get_generator_block(input_dim, output_dim):\n",
    "    '''\n",
    "    Function for returning a block of the generator's neural network\n",
    "    given input and output dimensions.\n",
    "    Parameters:\n",
    "        input_dim: the dimension of the input vector, a scalar\n",
    "        output_dim: the dimension of the output vector, a scalar\n",
    "    Returns:\n",
    "        a generator neural network layer, with a linear transformation \n",
    "          followed by a batch normalization and then a relu activation\n",
    "    '''\n",
    "    return nn.Sequential(\n",
    "        # Hint: Replace all of the \"None\" with the appropriate dimensions.\n",
    "        # The documentation may be useful if you're less familiar with PyTorch:\n",
    "        # https://pytorch.org/docs/stable/nn.html.\n",
    "        #### START CODE HERE ####\n",
    "        nn.Linear(input_dim, output_dim),\n",
    "        nn.BatchNorm1d(output_dim),\n",
    "        nn.ReLU(inplace=True),\n",
    "        #### END CODE HERE ####\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, hidden_dim, noise_dim, img_dim):\n",
    "        super(Generator, self).__init__()\n",
    "        self.gen = nn.Sequential(\n",
    "            nn.Linear(noise_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.Linear(hidden_dim, hidden_dim*2),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.Linear(hidden_dim*2, hidden_dim*4),\n",
    "            nn.BatchNorm1d(hidden_dim*4),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.Linear(hidden_dim*4, img_dim),\n",
    "            nn.Sigmoid()\n",
    "            \n",
    "        )\n",
    "        \n",
    "    def forward(self, noise):\n",
    "         return gen(noise)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    '''\n",
    "    Generator Class\n",
    "    Values:\n",
    "        z_dim: the dimension of the noise vector, a scalar\n",
    "        im_dim: the dimension of the images, fitted for the dataset used, a scalar\n",
    "          (MNIST images are 28 x 28 = 784 so that is your default)\n",
    "        hidden_dim: the inner dimension, a scalar\n",
    "    '''\n",
    "    def __init__(self, z_dim=10, im_dim=784, hidden_dim=128):\n",
    "        super(Generator, self).__init__()\n",
    "        # Build the neural network\n",
    "        self.gen = nn.Sequential(\n",
    "            get_generator_block(z_dim, hidden_dim),\n",
    "            get_generator_block(hidden_dim, hidden_dim * 2),\n",
    "            get_generator_block(hidden_dim * 2, hidden_dim * 4),\n",
    "            get_generator_block(hidden_dim * 4, hidden_dim * 8),\n",
    "            # There is a dropdown with hints if you need them! \n",
    "            #### START CODE HERE ####\n",
    "            nn.Linear(hidden_dim*8, im_dim),\n",
    "            nn.Sigmoid(),\n",
    "            #### END CODE HERE ####\n",
    "        )\n",
    "    def forward(self, noise):\n",
    "        '''\n",
    "        Function for completing a forward pass of the generator: Given a noise tensor, \n",
    "        returns generated images.\n",
    "        Parameters:\n",
    "            noise: a noise tensor with dimensions (n_samples, z_dim)\n",
    "        '''\n",
    "        return self.gen(noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, img_dim, hidden_dim, slope):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.disc = nn.Sequential(\n",
    "            \n",
    "            nn.Linear(img_dim, hidden_dim*16),\n",
    "            nn.BatchNorm1d(hidden_dim*16),\n",
    "            nn.LeakyReLU(slope),\n",
    "            \n",
    "            nn.Linear(hidden_dim*16, hidden_dim*8),\n",
    "            nn.BatchNorm1d(hidden_dim*8),\n",
    "            nn.LeakyReLU(slope),\n",
    "            \n",
    "            nn.Linear(hidden_dim*8, hidden_dim*4),\n",
    "            nn.BatchNorm1d(hidden_dim*4),\n",
    "            nn.LeakyReLU(slope),\n",
    "            \n",
    "            nn.Linear(hidden_dim*4, 1),\n",
    "        )\n",
    "    def forward(self, image):\n",
    "        return self.disc(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    '''\n",
    "    Discriminator Class\n",
    "    Values:\n",
    "        im_dim: the dimension of the images, fitted for the dataset used, a scalar\n",
    "            (MNIST images are 28x28 = 784 so that is your default)\n",
    "        hidden_dim: the inner dimension, a scalar\n",
    "    '''\n",
    "    def __init__(self, im_dim=784, hidden_dim=128):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.disc = nn.Sequential(\n",
    "            get_discriminator_block(im_dim, hidden_dim * 4),\n",
    "            get_discriminator_block(hidden_dim * 4, hidden_dim * 2),\n",
    "            get_discriminator_block(hidden_dim * 2, hidden_dim),\n",
    "            # Hint: You want to transform the final output into a single value,\n",
    "            #       so add one more linear map.\n",
    "            #### START CODE HERE ####\n",
    "            nn.Linear(hidden_dim, 1),\n",
    "            #### END CODE HERE ####\n",
    "        )\n",
    "\n",
    "    def forward(self, image):\n",
    "        '''\n",
    "        Function for completing a forward pass of the discriminator: Given an image tensor, \n",
    "        returns a 1-dimension tensor representing fake/real.\n",
    "        Parameters:\n",
    "            image: a flattened image tensor with dimension (im_dim)\n",
    "        '''\n",
    "        return self.disc(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_noise(n_samples, noise_dim, device='cpu'):\n",
    "    noise = torch.randn(n_samples, noise_dim, device=device)\n",
    "    return noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_dim = (128, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Set your parameters\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "n_epochs = 200\n",
    "z_dim = 64\n",
    "display_step = 500\n",
    "batch_size = 128\n",
    "lr = 0.00001\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gen = Generator(hidden_dim = 128, noise_dim = z_dim, img_dim = 784).to(device=device)\n",
    "gen_opt = torch.optim.Adam(gen.parameters(), lr=lr)\n",
    "\n",
    "disc = Discriminator(img_dim = image_size, hidden_dim = 128, slope = 0.2).to(device=device)\n",
    "disc_opt = torch.optim.Adam(disc.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = Generator(z_dim).to(device)\n",
    "gen_opt = torch.optim.Adam(gen.parameters(), lr=lr)\n",
    "disc = Discriminator().to(device) \n",
    "disc_opt = torch.optim.Adam(disc.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## DEFINING DISCRIMINATOR AND GENERATOR LOSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_disc_loss(gen, disc, criterion, real_images, num_images, z_dim, device):\n",
    "    '''\n",
    "    gen = generator\n",
    "    disc = discriminator\n",
    "    criterion = loss function\n",
    "    real_images = batch of real images\n",
    "    num_images = number of image the generator is supposed to generate\n",
    "    z_dim = noise dimension\n",
    "    device = cuda or cpu\n",
    "    '''\n",
    "    noise_vecs = get_noise(num_images, z_dim, device = device)\n",
    "    fake_images = gen(noise_vecs)\n",
    "    \n",
    "    real_pred = disc(real_images)\n",
    "    fake_pred = disc(fake_images.detach())\n",
    "    \n",
    "    loss_real = criterion(real_pred, torch.ones_like(real_pred))\n",
    "    loss_fake = criterion(fake_pred, torch.zeros_like(fake_pred))\n",
    "    \n",
    "    disc_loss = (loss_real + loss_fake) /2\n",
    "    return disc_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gen_loss(gen, disc, criterion, num_images, z_dim, device):\n",
    "    '''\n",
    "    gen = generator\n",
    "    disc = discriminator\n",
    "    criterion = loss function\n",
    "    real_images = batch of real images\n",
    "    num_images = number of image the generator is supposed to generate\n",
    "    z_dim = noise dimension\n",
    "    device = cuda or cpu\n",
    "    '''\n",
    "    noise_vecs = get_noise(num_images, z_dim, device=device)\n",
    "    fake_images = gen(noise_vecs)\n",
    "    \n",
    "    fake_pred = disc(fake_images)\n",
    "    gen_loss = criterion(fake_pred, torch.ones_like(fake_pred))\n",
    "    \n",
    "    return gen_loss\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from tqdm.auto import tqdm\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST # Training dataset\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def show_tensor_images(image_tensor, num_images=25, size=(1, 28, 28)):\n",
    "    '''\n",
    "    Function for visualizing images: Given a tensor of images, number of images, and\n",
    "    size per image, plots and prints the images in a uniform grid.\n",
    "    '''\n",
    "\n",
    "    image_unflat = image_tensor.detach().cpu().view(-1, *size)\n",
    "    image_grid = make_grid(image_unflat[:num_images], nrow=5)\n",
    "    plt.imshow(image_grid.permute(1, 2, 0).squeeze())\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "batch_size = 64\n",
    "dataloader = torch.utils.data.DataLoader( torchvision.datasets.MNIST('.', download=True, transform=transforms.ToTensor()),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "cur_step = 0\n",
    "mean_generator_loss = 0\n",
    "mean_discriminator_loss = 0\n",
    "test_generator = True # Whether the generator should be tested\n",
    "gen_loss = False\n",
    "error = False\n",
    "n_epochs = 100\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    \n",
    "    \n",
    "    for real,_ in tqdm(dataloader):\n",
    "        \n",
    "        curr_batch_size = len(real)\n",
    "        \n",
    "        # Flattening the batch \n",
    "        real = real.view(curr_batch_size, -1).to(device)\n",
    "        \n",
    "        ##### UPDATE DISCRIMINATOR ######\n",
    "        disc_opt.zero_grad()\n",
    "        disc_loss = get_disc_loss(gen, disc, criterion, real, curr_batch_size, z_dim, device)\n",
    "        disc_loss.backward(retain_graph=True)\n",
    "        disc_opt.step()\n",
    "        \n",
    "        #### UPDATE GENERATOR ######\n",
    "        gen_opt.zero_grad()\n",
    "        gen_loss = get_gen_loss(gen, disc, criterion, curr_batch_size, z_dim, device)\n",
    "        gen_loss.backward(retain_graph=True)\n",
    "        gen_opt.step()\n",
    "        \n",
    "        fake_noise = get_noise(curr_batch_size, z_dim, device=device)\n",
    "        fake = gen(fake_noise)\n",
    "        show_tensor_images(fake)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_block(input_dim, output_dim):\n",
    "    '''This function will give a combined layer consisting of \n",
    "    1) Linear layer.\n",
    "    2) Batch Regularization\n",
    "    3) Relu'''\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(input_dim, output_dim),\n",
    "        nn.BatchNorm1d(output_dim),\n",
    "        nn.ReLU(inplace=True),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator:\n",
    "    '''This block defines the generator, which uses the gen_block function to declare layers'''\n",
    "    def __init__(self, img_dim, hidden_dim, z_dim):\n",
    "        super(Generator, self).__init__()\n",
    "        self.gen = nn.Sequential(\n",
    "            gen_block(z_dim, hidden_dim),\n",
    "            gen_block(hidden_dim, hidden_dim*4),\n",
    "            gen_block(hidden_dim*4, hidden_dim*8),\n",
    "            gen_block(hidden_dim*8, hidden_dim*16),\n",
    "            gen_block(hidden_dim*16, img_dim),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, noise):\n",
    "        return gen(noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def disc_block(input_dim, output_dim, slope):\n",
    "    '''This function will give a combined layer consisting of\n",
    "    1) Linear layer\n",
    "    2) Leaky Relu'''\n",
    "    \n",
    "    return nn.Sequential(\n",
    "        nn.Linear(input_dim, output_dim),\n",
    "        nn.LeakyReLU(slope),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator:\n",
    "    '''This block defines the discriminator, which uses the disc_block function to declare layers'''\n",
    "    def __init__(self, img_dim, hidden_dim, z_dim):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.disc = nn.Sequential(\n",
    "            disc_block(img_dim, hidden_dim*16),\n",
    "            disc_block()\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
